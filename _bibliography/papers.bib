@article{ye_mitigating_2023,
    title = {Mitigating {Transformer} {Overconfidence} via {Lipschitz} {Regularization}},
    journal = {39th {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
    author = {Ye, Wenqian and Ma, Yunsheng and Cao, Xu and Tang, Kun},
    month = may,
    year = {2023},
    selected = {true},
    abbr = {UAI},
    teaser = {cover_mitigating.png},
}

@article{ma_cemformer_2023,
    title = {CEMFormer: Learning to Predict Driver Intentions from In-Cabin and External Cameras via Spatial-Temporal Transformers},
    author = {Yunsheng Ma and Wenqian Ye and Xu Cao and Amr Abdelraouf and Kyungtae Han and Rohit Gupta and Ziran Wang},
    journal = {arXiv:2305.07840},
    arxiv = {2305.07840},
    year = {2023},
    selected = {true},
    teaser = {cover_cemformer.png},
}

@article{cui_radar_2023,
    title = {Radar {Enlighten} the {Dark}: {Enhancing} {Low}-{Visibility} {Perception} for {Automated} {Vehicles} with {Camera}-{Radar} {Fusion}},
    author = {Cui, Can and Ma, Yunsheng and Lu, Juanwu and Wang, Ziran},
    journal = {arXiv:2305.17318},
    arxiv = {2305.17318},
    year = {2023},
    selected = {true},
    teaser = {cover_redformer.png},
}

@article{ma_vit-dd_2023,
    title = {{ViT}-{DD}: {Multi}-{Task} {Vision} {Transformer} for {Semi}-{Supervised} {Driver} {Distraction} {Detection}},
    journal = {{IEEE} {Intelligent} {Vehicles} {Symposium}},
    author = {Ma, Yunsheng and Wang, Ziran},
    year = {2023},
    selected = {true},
    abbr = {IEEE-IV},
    teaser = {cover_vit-dd.png},
    code = {https://github.com/PurdueDigitalTwin/ViT-DD},
    arxiv = {2209.09178},
    workshop = {Presented at <b>NeurIPS ML4AD</b> <a href="/news/2022-12-03-ml4ad">[News]</a>},
}


@article{ma_m2dar_2023,
    title = {{M2DAR}: {Multi}-{View} {Multi}-{Scale} {Driver} {Action} {Recognition} with {Vision} {Transformer}},
    journal = {{IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops}},
    author = {Ma, Yunsheng and Yuan, Liangqi and Abdelraouf, Amr and Han, Kyungtae and Gupta, Rohit and Li, Zihao and Wang, Ziran},
    year = {2023},
    selected = {true},
    abbr = {CVPRW},
    teaser = {cover_m2dar.png},
    arxiv = {2305.08877},
    award = {Outstanding Student Presentation Award at NGTS <a href="/news/2023-05-18-ngts3/">[News]</a>},
    code = {https://github.com/PurdueDigitalTwin/M2DAR},
}

@article{yuan_peer--peer_2023,
    title = {Peer-to-{Peer} {Federated} {Continual} {Learning} for {Naturalistic} {Driving} {Action} {Recognition}},
    journal = {{IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops}},
    author = {Yuan, Liangqi and Ma, Yunsheng and Su, Lu and Wang, Ziran},
    year = {2023},
    selected = {false},
    abbr = {CVPRW},
    teaser = {cover_p2p.png},
    arxiv = {2304.07421},
}

@article{zhao_vaanet_2020,
    title = {An {End}-to-{End} {Visual}-{Audio} {Attention} {Network} for {Emotion} {Recognition} in {User}-{Generated} {Videos}},
    journal = {{AAAI} {Conference} on {Artificial} {Intelligence}},
    author = {Zhao*, Sicheng and Ma*, Yunsheng and Gu, Yang and Yang, Jufeng and Xing, Tengfei and Xu, Pengfei and Hu, Runbo and Chai, Hua and Keutzer, Kurt},
    year = {2020},
    selected = {true},
    abbr = {AAAI Oral},
    pdf = {https://ojs.aaai.org/index.php/AAAI/article/view/5364},
    code = {https://github.com/maysonma/VAANet},
    teaser = {cover_vaanet.png},
    arxiv = {2003.00832},
}
