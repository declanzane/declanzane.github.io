<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- Metadata, OpenGraph and Schema.org -->


    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Publications | Yunsheng  Ma</title>
    <meta name="author" content="Yunsheng  Ma">
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


<!-- Bootstrap & MDB -->
<link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

<!-- Bootstrap Table -->
<link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.css">

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css">
<!--      href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css"-->
<!--      integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">-->
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">



<!-- Styles -->

<link rel="shortcut icon" href="/assets/img/uni.png">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="https://maysonma.github.io//publications/">

<!-- Dark Mode -->

<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>


  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Yunsheng </span>Ma</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About me</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Publications</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
<h2 class="year">2024</h2>
<ol class="bibliography">
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_lampilot.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">CVPR</abbr>
        
        
    </div>

    <div id="ma_lampilot_2024" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">LaMPilot: An Open Benchmark Dataset for Autonomous Driving with Language Model Programs</div>
        <!-- Author -->
        <div class="author">
            <em><b>Yunsheng Ma*</b></em>, <a href="https://cancui19.github.io/" rel="external nofollow noopener" target="_blank">Can Cui*</a>, <a href="https://www.irohxucao.com/" rel="external nofollow noopener" target="_blank">Xu Cao*</a>, <a href="https://wenqian-ye.github.io/" rel="external nofollow noopener" target="_blank">Wenqian Ye</a>, Peiran Liu, <a href="https://www.linkedin.com/in/juanwu-lu/" rel="external nofollow noopener" target="_blank">Juanwu Lu</a>, Amr Abdelraouf, Rohit Gupta, Kyungtae Han, <a href="https://www.cs.purdue.edu/homes/ab/" rel="external nofollow noopener" target="_blank">Aniket Bera</a>, <a href="https://rehg.org/" rel="external nofollow noopener" target="_blank">James M. Rehg</a>, and <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>
            
        </div>
        <div class="periodical">
            
            <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>
            
            
            (<b>CVPR</b>)
            
            
            , 2024
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_maplm.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">CVPR</abbr>
        
        
    </div>

    <div id="cao_maplm_2024" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">MAPLM: A Real-World Large-Scale Vision-Language Dataset for Map and Traffic Scene Understanding</div>
        <!-- Author -->
        <div class="author">
<a href="https://www.irohxucao.com/" rel="external nofollow noopener" target="_blank">Xu Cao*</a>, Tong Zhou*, 
            <em><b>Yunsheng Ma*</b></em>, <a href="https://wenqian-ye.github.io/" rel="external nofollow noopener" target="_blank">Wenqian Ye</a>, <a href="https://cancui19.github.io/" rel="external nofollow noopener" target="_blank">Can Cui</a>, Kun Tang, Zhipeng Cao, Kaizhao Liang, <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>, <a href="https://rehg.org/" rel="external nofollow noopener" target="_blank">James M. Rehg</a>, and Chao Zheng
        </div>
        <div class="periodical">
            
            <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>
            
            
            (<b>CVPR</b>)
            
            
            , 2024
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_seneva.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">CVPR</abbr>
        
        
    </div>

    <div id="lu_quantifying_2024" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">Quantifying Uncertainty in Motion Prediction with Variational Bayesian Mixture</div>
        <!-- Author -->
        <div class="author">
<a href="https://www.linkedin.com/in/juanwu-lu/" rel="external nofollow noopener" target="_blank">Juanwu Lu*</a>, <a href="https://cancui19.github.io/" rel="external nofollow noopener" target="_blank">Can Cui*</a>, 
            <em><b>Yunsheng Ma</b></em>, <a href="https://www.cs.purdue.edu/homes/ab/" rel="external nofollow noopener" target="_blank">Aniket Bera</a>, and <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>
            
        </div>
        <div class="periodical">
            
            <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>
            
            
            (<b>CVPR</b>)
            
            
            , 2024
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_macp.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">WACV</abbr>
        
        
    </div>

    <div id="ma_macp_2024" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">MACP: Efficient Model Adaptation for Cooperative Perception</div>
        <!-- Author -->
        <div class="author">
            <em><b>Yunsheng Ma*</b></em>, <a href="https://www.linkedin.com/in/juanwu-lu/" rel="external nofollow noopener" target="_blank">Juanwu Lu*</a>, <a href="https://cancui19.github.io/" rel="external nofollow noopener" target="_blank">Can Cui</a>, <a href="https://sites.google.com/view/schzhao" rel="external nofollow noopener" target="_blank">Sicheng Zhao</a>, <a href="https://www.irohxucao.com/" rel="external nofollow noopener" target="_blank">Xu Cao</a>, <a href="https://wenqian-ye.github.io/" rel="external nofollow noopener" target="_blank">Wenqian Ye</a>, and <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>
            
        </div>
        <div class="periodical">
            
            <em>In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em>
            
            
            (<b>WACV</b>)
            
            
            , 2024
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            
            
            <a href="http://arxiv.org/abs/2310.16870" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
            
            
            
            
            
            
            <a href="https://github.com/PurdueDigitalTwin/MACP" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
            
            
            
            
            
            <a href="https://purduedigitaltwin.github.io/MACP/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Website</a>
            
        </div>

        <!-- Hidden abstract block -->
        
        <div class="abstract hidden">
            <p>Vehicle-to-vehicle (V2V) communications have greatly enhanced the perception capabilities of connected and automated vehicles (CAVs) by enabling information sharing to “see through the occlusions", resulting in significant performance improvements. However, developing and training complex multi-agent perception models from scratch can be expensive and unnecessary when existing single-agent models show remarkable generalization capabilities. In this paper, we propose a new framework termed MACP, which equips a single-agent pre-trained model with cooperation capabilities. We approach this objective by identifying the key challenges of shifting from single-agent to cooperative settings, adapting the model by freezing most of its parameters and adding a few lightweight modules. We demonstrate in our experiments that the proposed framework can effectively utilize cooperative observations and outperform other state-of-the-art approaches in both simulated and real-world cooperative perception benchmarks while requiring substantially fewer tunable parameters with reduced communication costs.</p>
        </div>
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_ddt.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">T-IV</abbr>
        
        
    </div>

    <div id="ma_driver_2024" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">Driver Digital Twin for Online Recognition of Distracted Driving Behaviors</div>
        <!-- Author -->
        <div class="author">
            <em><b>Yunsheng Ma</b></em>, Runjia Du, Amr Abdelraouf, Kyungtae Han, Rohit Gupta, and <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>
            
        </div>
        <div class="periodical">
            
            <em>IEEE Transactions on Intelligent Vehicles</em>
            
            
            (<b>T-IV</b>)
            
            
            , 2024
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
</ol>

<h2 class="year">2023</h2>
<ol class="bibliography">
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_redformer.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">T-IV</abbr>
        
        
    </div>

    <div id="cui_redformer_2023" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">REDFormer: Radar Enlightens the Darkness of Camera Perception With Transformers</div>
        <!-- Author -->
        <div class="author">
<a href="https://cancui19.github.io/" rel="external nofollow noopener" target="_blank">Can Cui</a>, 
            <em><b>Yunsheng Ma</b></em>, <a href="https://www.linkedin.com/in/juanwu-lu/" rel="external nofollow noopener" target="_blank">Juanwu Lu</a>, and <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>
            
        </div>
        <div class="periodical">
            
            <em>IEEE Transactions on Intelligent Vehicles</em>
            
            
            (<b>T-IV</b>)
            
            
            , 2023
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_mitigating.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">UAI</abbr>
        
        
    </div>

    <div id="ye_mitigating_2023" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">Mitigating Transformer Overconfidence via Lipschitz Regularization</div>
        <!-- Author -->
        <div class="author">
<a href="https://wenqian-ye.github.io/" rel="external nofollow noopener" target="_blank">Wenqian Ye</a>, 
            <em><b>Yunsheng Ma</b></em>, <a href="https://www.irohxucao.com/" rel="external nofollow noopener" target="_blank">Xu Cao</a>, and Kun Tang
        </div>
        <div class="periodical">
            
            <em>In Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence</em>
            
            
            (<b>UAI</b>)
            
            
            , 2023
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            
            
            <a href="http://arxiv.org/abs/2306.06849" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        
        <div class="abstract hidden">
            <p>Though Transformers have achieved promising results in many computer vision tasks, they tend to be over-confident in predictions, as the standard Dot Product Self-Attention (DPSA) can barely preserve distance for the unbounded input domain. In this work, we fill this gap by proposing a novel Lipschitz Regularized Transformer (LRFormer). Specifically, we present a new similarity function with the distance within Banach Space to ensure the Lipschitzness and also regularize the term by a contractive Lipschitz Bound. The proposed method is analyzed with a theoretical guarantee, providing a rigorous basis for its effectiveness and reliability. Extensive experiments conducted on standard vision benchmarks demonstrate that our method outperforms state-of-the-art single forward pass approaches in prediction, calibration, and uncertainty estimation.</p>
        </div>
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_cemformer.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">ITSC</abbr>
        
        
    </div>

    <div id="ma_cemformer_2023" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">CEMFormer: Learning to Predict Driver Intentions from In-Cabin and External Cameras via Spatial-Temporal Transformers</div>
        <!-- Author -->
        <div class="author">
            <em><b>Yunsheng Ma</b></em>, <a href="https://wenqian-ye.github.io/" rel="external nofollow noopener" target="_blank">Wenqian Ye</a>, <a href="https://www.irohxucao.com/" rel="external nofollow noopener" target="_blank">Xu Cao</a>, Amr Abdelraouf, Kyungtae Han, Rohit Gupta, and <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>
            
        </div>
        <div class="periodical">
            
            <em>In IEEE International Conference on Intelligent Transportation Systems</em>
            
            
            (<b>ITSC</b>)
            
            
            , 2023
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            
            <a href="http://arxiv.org/abs/2305.07840" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_m2dar.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">CVPRW</abbr>
        
        
    </div>

    <div id="ma_m2dar_2023" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">M2DAR: Multi-View Multi-Scale Driver Action Recognition with Vision Transformer</div>
        <!-- Author -->
        <div class="author">
            <em><b>Yunsheng Ma</b></em>, <a href="https://liangqiy.com/" rel="external nofollow noopener" target="_blank">Liangqi Yuan</a>, Amr Abdelraouf, Kyungtae Han, Rohit Gupta, Zihao Li, and <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>
            
        </div>
        <div class="periodical">
            
            <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</em>
            
            
            (<b>CVPRW</b>)
            
            
            , 2023
            
            
            <br><b style="color:#8E0C24">Outstanding Speaker Award at NGTS <a href="/news/2023-05-18-ngts3/">[News]</a></b>
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            
            <a href="http://arxiv.org/abs/2305.08877" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
            
            
            
            
            
            
            <a href="https://github.com/PurdueDigitalTwin/M2DAR" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_p2p.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">CVPRW</abbr>
        
        
    </div>

    <div id="yuan_peer--peer_2023" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">Peer-to-Peer Federated Continual Learning for Naturalistic Driving Action Recognition</div>
        <!-- Author -->
        <div class="author">
<a href="https://liangqiy.com/" rel="external nofollow noopener" target="_blank">Liangqi Yuan</a>, 
            <em><b>Yunsheng Ma</b></em>, <a href="https://engineering.purdue.edu/~lusu/" rel="external nofollow noopener" target="_blank">Lu Su</a>, and <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>
            
        </div>
        <div class="periodical">
            
            <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</em>
            
            
            (<b>CVPRW</b>)
            
            
            , 2023
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            
            <a href="http://arxiv.org/abs/2304.07421" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
</ol>

<h2 class="year">2020</h2>
<ol class="bibliography"><li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_vaanet.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">AAAI Oral</abbr>
        
        
    </div>

    <div id="zhao_vaanet_2020" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">An End-to-End Visual-Audio Attention Network for Emotion Recognition in User-Generated Videos</div>
        <!-- Author -->
        <div class="author">
<a href="https://sites.google.com/view/schzhao" rel="external nofollow noopener" target="_blank">Sicheng Zhao*</a>, 
            <em><b>Yunsheng Ma*</b></em>, Yang Gu, Jufeng Yang, Tengfei Xing, Pengfei Xu, Runbo Hu, Hua Chai, and <a href="https://people.eecs.berkeley.edu/~keutzer/" rel="external nofollow noopener" target="_blank">Kurt Keutzer</a>
            
        </div>
        <div class="periodical">
            
            <em>In Proceedings of the AAAI Conference on Artificial Intelligence</em>
            
            
            (<b>AAAI Oral</b>)
            
            
            , 2020
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            
            <a href="http://arxiv.org/abs/2003.00832" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
            
            
            
            
            
            
            <a href="https://github.com/maysonma/VAANet" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
            
            
            
            
            
            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5364" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Website</a>
            
        </div>

        <!-- Hidden abstract block -->
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li></ol>


</div>

          </article>

        </div>

      
    </div>

    <!-- Footer --><footer class="sticky-bottom mt-5">
    <div class="container">
        <a href="https://www.easycounter.com/" rel="external nofollow noopener" target="_blank">
            <img src="https://www.easycounter.com/counter.php?maysonma" border="0" alt="HTML Hit Counters"></a>
        unique visitors since May 2023.
    </div>
    <div class="container">
        © Copyright 2024 Yunsheng  Ma.
        Last updated: March 21, 2024.
    </div>

</footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-EZGH5PJVSL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-EZGH5PJVSL');
  </script>
    

  </body>
</html>
